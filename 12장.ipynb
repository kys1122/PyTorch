{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa7c823-1d89-40fa-8cca-d78e7f02c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ea5d74-18ee-4976-bc0a-713bc50dc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1').unwrapped\n",
    "plt.ion()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da0773a-2e0b-40f9-86b3-0eb38e17d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6f9ca6-a488-4845-b5d8-e9064f41ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_fname = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font_family = font_manager.FontProperties(fname=font_fname).get_name()\n",
    "plt.rcParams[\"font.family\"] = font_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c507d6c5-23c4-4ad1-9197-db52b82cce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c74c638-0551-419d-a0e2-09ef1b6d2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        def conv2d_size_out(size, kernel_size=5, stride=2):\n",
    "            return(size-(kernel_size-1)-1) // stride+1\n",
    "\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae09d00-c6f6-4d76-a1e5-fdcdd768754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de077eae-6e7d-43d7-a9fe-0d73bb80e44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\516-29\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "\n",
    "resize = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize(40, interpolation=Image.BICUBIC),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.unwrapped.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.unwrapped.state[0] * scale + screen_width / 2.0)\n",
    "\n",
    "def get_screen():\n",
    "    frame = env.render()\n",
    "    screen = frame.transpose((2, 0, 1))\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height*0.8)]\n",
    "    view_width = int(screen_width*0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2, cart_location + view_width // 2)\n",
    "\n",
    "    screen = screen[:, :, slice_range]\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "obs, _ = env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(), interpolation='none')\n",
    "plt.title('화면 예시')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0144e8a6-c380-449f-8f23-a14ac5470ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "init_screen = get_screen()\n",
    "_, _, screen_hight, screen_width = init_screen.shape\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_hight, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_hight, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06175170-baac-4b80-8a1b-3c2f65d982e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2b5eab-5af8-433a-8315-15829740a0a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'function' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m current_screen \u001b[38;5;241m=\u001b[39m get_screen\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 24\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m (\u001b[43mcurrent_screen\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlast_screen\u001b[49m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'function' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "\n",
    "train_env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "view_env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    obs, info = train_env.reset()\n",
    "    view_env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "\n",
    "    for t in count():\n",
    "        view_env.render()\n",
    "        action = select_action(state)\n",
    "        obs, reward, terminated, truncated, info = train_env.step(action.item())\n",
    "        done = terminated or truncated\n",
    "\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen\n",
    "\n",
    "        if not done:\n",
    "            next_state = (current_screen-last_screen)\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "        optimize_model()\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            break\n",
    "\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "\n",
    "train_env.close()\n",
    "view_env.close()\n",
    "print('종료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b323ee1-40b9-4cf6-abde-3b51d99fc0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_book",
   "language": "python",
   "name": "tf2_book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
